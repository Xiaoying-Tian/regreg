{
 "metadata": {
  "name": "Distributed LASSO: ADMM"
 },
 "nbformat": 3,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "source": [
      "",
      "",
      "From http://www.stanford.edu/~boyd/papers/pdf/admm_distr_stats.pdf.",
      "Specifically, on p. 70 $\\S$ 8.1.3, making the substitutions",
      "$x_i=\\beta_i, z_i=\\mu_i$.",
      "",
      "",
      "$$",
      "   \\newcommand{\\argmin}{\\mathop{argmin}}",
      "   \\begin{aligned}",
      "   \\beta_i^{k+1} &= \\argmin_{\\beta_i} \\left(\\frac{\\rho}{2} \\|X_i\\beta_i-X_i\\beta_i^k - \\bar{\\mu}^k + \\bar{X\\beta}^k + u^k\\|^2_2 + \\lambda\\|\\beta_i\\|_1 \\right) \\\\\\",
      "   \\bar{\\mu}^{k+1} &= \\frac{1}{N+\\rho} \\left(y + \\rho \\bar{X\\beta}^k + \\rho u^k\\right) \\\\\\",
      "   u^{k+1} &= u^k + \\bar{X\\beta}^k - \\bar{\\mu}^{k+1}",
      "   \\end{aligned}",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext parallelmagic",
      "from IPython.parallel import Client",
      "rc = Client()",
      "dview = rc[:]",
      "dview.activate()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%px",
      "import regreg.api as R",
      "import regreg.paths as RP",
      "import numpy as np",
      "",
      "# np.random.seed(1)  # for debugging",
      "",
      "class loss_factory(RP.squared_error_factory):",
      "    ",
      "    def __init__(self, response, rho=1.):",
      "        RP.squared_error_factory.__init__(self, response)",
      "        self.rho = rho",
      "        ",
      "    def __call__(self, X):",
      "        n = self.response.shape[0]",
      "        return R.squared_error(X, -self.response, coef=self.rho/n)",
      ""
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Async parallel execution on engine(s): [0, 1, 2, 3]",
        ""
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<AsyncResult: execute>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@dview.remote()",
      "def myfunc(arg):",
      "    print arg",
      "    "
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "[IPython.parallel.error.TaskAborted(u'fc304bc3-9180-4aed-9ffa-7fd9352b0284'),",
        " None,",
        " None,",
        " None]"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px myfunc('blah')"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Async parallel execution on engine(s): [0, 1, 2, 3]",
        ""
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<AsyncResult: execute>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':",
      "    import os.path",
      "",
      "    # Load IPython parallel resources, a cluster should have been instantiated",
      "    from IPython.parallel import Client",
      "    rc = Client()",
      "    # We actually work with the view, in this case using all engines",
      "    view = rc[:]",
      "    # Use the view in synchronous mode, we don't have any major space below for",
      "    # overlapping local and remote computation, and this is easier to work with",
      "    view.block = True",
      "",
      "    @view.remote()",
      "    def update_lasso_nodes(pseudo_response, tol):",
      "        node.response = node.fitted + pseudo_response",
      "        node.solver.fit(max_its=1000, min_its=10, tol=tol)",
      "        beta[:] = node.beta",
      "        return node.fitted",
      "",
      "    def update_global_variables(lasso_fits, y, u, rho):",
      "        # this is a reduction operation",
      "        Xbeta_bar = np.mean(lasso_fits, 0)",
      "",
      "        N = len(lasso_fits)",
      "        mu_bar = (y + rho * (Xbeta_bar + u)) / (N + rho)",
      "        u = u + Xbeta_bar - mu_bar",
      "        return Xbeta_bar, mu_bar, u",
      "",
      "    def objective(beta, X, Y, l):",
      "        return np.linalg.norm(Y - np.dot(X, beta))**2 / 2. + \\",
      "               l * np.fabs(beta).sum()",
      "",
      "    # generate a data matrix",
      "    n, p = (500, 400)",
      "    X = np.random.standard_normal((n, p))",
      "    beta = 10 * np.ones(p)",
      "    beta[200:] = 0",
      "    Y = np.dot(X, beta) + np.random.standard_normal(n)",
      "",
      "    # Scatter works on the first dimension, and we want to break things up by",
      "    # columns, so we transpose before scattering and transpo",
      "    view.scatter('Xt', X.T)",
      "",
      "    @view.remote()",
      "    def node_init(lagrange, path):",
      "        global node, beta",
      "        import os",
      "        import numpy as np",
      "        os.chdir(path)",
      "        import distributed_lasso as dl",
      "",
      "        #np.random.seed(1) # for debugging",
      "        node = dl.LassoNode(Xt.T, lagrange=lagrange)",
      "        beta = np.empty(Xt.shape[0])",
      "",
      "    # the Lagrange penalty parameter, lambda",
      "    lagrange = 40.",
      "    mu_bar = 0 * Y",
      "    Xbeta_bar = 0 * Y",
      "    u = 0 * Y",
      "    rho = 1.",
      "    tol = 1.0e-10",
      "",
      "    # This initializes all the nodes and creates the Lasso objects",
      "    node_init(lagrange, os.path.dirname(os.path.abspath(__file__)))",
      "    ",
      "    old_obj = np.inf",
      "    for i in range(2000):",
      "        lasso_fits = update_lasso_nodes(mu_bar - Xbeta_bar - u, tol)",
      "        Xbeta_bar, mu_bar, u = update_global_variables(lasso_fits, Y, u, rho)",
      "        beta = view.gather('beta')",
      "        new_obj = objective(beta, X, Y, l)",
      "        if np.fabs(old_obj-new_obj) / np.fabs(new_obj) < tol:",
      "            break",
      "        old_obj = new_obj",
      "        print 'Iteration %d, objective %0.2f' % (i, new_obj)",
      "",
      "    #np.random.seed(1) # for debugging",
      "",
      "    penalty = R.l1norm(p, lagrange=lagrange)",
      "    loss = R.quadratic.affine(-X, Y, lagrange=0.5)",
      "    lasso = R.container(loss, penalty)",
      "    solver = R.FISTA(lasso.problem())",
      "    solver.fit(tol=tol)",
      "",
      "    lasso_soln = solver.problem.coefs",
      "    distributed_soln = beta"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'np' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-3125461967f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# generate a data matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    }
   ]
  }
 ]
}